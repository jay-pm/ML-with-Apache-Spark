# ML-with-Apache-Spark


**Machine learning with Apache Spark:**

Spark is a distributed computing platform for working with Big Data. It achieves efficiency by distributing data and computation across a cluster of computers. Spark is currently the best framework for cluster computing. Spark transparently handles the distribution of compute tasks across a cluster. Spark operations are fast and it also allows us to focus on the analysis rather than worry about technical details.

As per Apache Spark official website spark has below advantages over other available tools (hadoop, mapreduce) in market:

- Speed: Run workloads 100x faster [for both batch and streaming data]
- Ease of Use: Write applications quickly in Java, Scala, Python, R, and SQL.
- Generality: Combine SQL, streaming, and complex analytics.
- Runs Everywhere: Spark runs on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud. It can access diverse data sources.

**Contents:**
1.	Apache Spark basics
2.	Creating a session and connecting with spark
3.	Loading data and data pre-processing
4.	Building ML models (Classification and Regression)
5.	Tuning ML models for performance improvement
6.	Build pipeline for ML model
7.	Ensemble models

